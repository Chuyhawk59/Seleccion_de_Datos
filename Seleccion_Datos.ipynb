{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036f307a-e053-4819-b964-1611c5c02d38",
   "metadata": {},
   "source": [
    "Para empezar a seleccionar los datos primero tenemos que leerlos. Para esto se usa la libreria de `pandas` para leer la base de datos. Luego imprimimos algunos datos para revisar si podría existir una relacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a25bb618-367f-45fe-bf9c-7fe994fedb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (1599, 12)\n",
      "Primeras 5 filas de datos:\n",
      "   acidezFija  acidezVolatil  acidoCitrico  azucarResidual  cloruros  \\\n",
      "0         7.4           0.70          0.00             1.9     0.076   \n",
      "1         7.8           0.88          0.00             2.6     0.098   \n",
      "2         7.8           0.76          0.04             2.3     0.092   \n",
      "3        11.2           0.28          0.56             1.9     0.075   \n",
      "4         7.4           0.70          0.00             1.9     0.076   \n",
      "\n",
      "   dioxidoAzufreLibre  dioxidoAzufreTotal  densidad    pH  sulfatos  alcohol  \\\n",
      "0                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "1                25.0                67.0    0.9968  3.20      0.68      9.8   \n",
      "2                15.0                54.0    0.9970  3.26      0.65      9.8   \n",
      "3                17.0                60.0    0.9980  3.16      0.58      9.8   \n",
      "4                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "\n",
      "   calidad  \n",
      "0        5  \n",
      "1        5  \n",
      "2        5  \n",
      "3        6  \n",
      "4        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Vino_Tinto.csv\")\n",
    "print(\"Dimensiones:\", data.shape)\n",
    "print(\"Primeras 5 filas de datos:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83755de-e1fd-4d7a-adba-687cec772c26",
   "metadata": {},
   "source": [
    "Ahora tenemos que separar los datos de entrenamiento y de prueba de la base de datos. Para este problema usaremos una separación 80/20, donde el 80% son los datos de entrenamiento y el 20% son los datos de prueba. Estos datos se deben elegir aleatoriamente, para esto se usa la funcion `train_test_split`. Recordemos que queremos saber que causa el cambio en calidad, por esto nuestra variable Y será la calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5152214-62fc-4ff8-a42f-b72e24131375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, train_size = 0.8)\n",
    "X_train = train.drop('calidad', axis = 1)\n",
    "X_test = test.drop('calidad', axis = 1)\n",
    "Y_train = train.calidad\n",
    "Y_test = test.calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40d3a3-4b82-431b-a57b-60f002e81cdb",
   "metadata": {},
   "source": [
    "Ya con los datos separados podemos proceder a la selección de variables. En el siguiente código realizaremos una selección hacia adelante. Para esto utilizaremos dos funciones: `LinearRegression` y `SequentialFeatureSelector`. La primera nos permite crear un estimador de regresión lineal, mientras que la segunda se encarga de ejecutar el proceso de selección de características.\n",
    "\n",
    "En la función `SequentialFeatureSelector` definimos varios parámetros: el estimador (nuestro modelo de regresión lineal), el rango de características a elegir (`k_features`), la opción de selección hacia adelante (`forward=True`), la métrica de evaluación que en este caso será $R^2$ (`scoring=\"r2\"`) y una validación cruzada de 5 folds (`cv=5`).\n",
    "\n",
    "Finalmente, ajustamos este selector con nuestros datos de entrenamiento y mostramos los nombres de las mejores características seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8ed5fc-4b48-4100-8ca5-e421f12fcc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores características hacia delante (nombres): ('acidezVolatil', 'azucarResidual', 'cloruros', 'dioxidoAzufreLibre', 'dioxidoAzufreTotal', 'pH', 'sulfatos', 'alcohol')\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "estimator = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=estimator,\n",
    "    k_features=(2, 8),\n",
    "    forward=True,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "sfs = sfs.fit(X_train, Y_train)\n",
    "print(\"Mejores características hacia delante (nombres):\", sfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adec202-e9fe-4e31-a2f0-b962191a7982",
   "metadata": {},
   "source": [
    "Ahora evaluaremos la calidad del mejor modelo obtenido mediante la selección hacia adelante. Para esto, utilizaremos la combinación de variables elegidas tanto en los datos de entrenamiento como en los de prueba. Posteriormente, entrenamos nuestro modelo con la variable de salida en el conjunto de entrenamiento y realizamos las predicciones sobre el conjunto de prueba.\n",
    "\n",
    "Finalmente, importamos la función `r2_score` para calcular el valor de $R^2$, que nos permitirá medir qué tan bien se ajusta el modelo a los datos. Por último, imprimimos este resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780937d6-ccd5-4ed4-aa80-a67b2bcf81cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 del modelo con las variables seleccionadas: 0.3229070119862125\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = X_train[list(sfs.k_feature_names_)]\n",
    "X_test_selected = X_test[list(sfs.k_feature_names_)]\n",
    "\n",
    "estimator.fit(X_train_selected, Y_train)\n",
    "Y_pred = estimator.predict(X_test_selected)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_1 = r2_score(Y_test, Y_pred)\n",
    "print(\"R^2 del modelo con las variables seleccionadas:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ecfaa8-c26e-47a1-89ad-580e7fab6250",
   "metadata": {},
   "source": [
    "Ahora repetiremos el mismo procedimiento que con la selección hacia adelante, pero esta vez modificaremos un parámetro: forward=False. Con este cambio realizaremos la selección hacia atrás, lo que nos permitirá eliminar variables poco relevantes y comparar posteriormente cuál método ofrece un mejor modelo.\n",
    "\n",
    "En este caso, también definimos el rango de características a elegir, el estimador de regresión lineal, la métrica de evaluación ($R^2$) y una validación cruzada de 5 folds. Finalmente, ajustamos el selector con los datos de entrenamiento e imprimimos los nombres de las características seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3cd23ad-1451-4dab-a499-4f425fd09633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores características hacia atras (nombres): ('acidezVolatil', 'cloruros', 'dioxidoAzufreTotal', 'sulfatos', 'alcohol')\n"
     ]
    }
   ],
   "source": [
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=estimator,\n",
    "    k_features=(2, 5),\n",
    "    forward=False,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "sfs = sfs.fit(X_train, Y_train)\n",
    "print(\"Mejores características hacia atras (nombres):\", sfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25b38f-c510-4df5-9580-532e72845a31",
   "metadata": {},
   "source": [
    "Igual que con la seleccion hacia delante obtenemos la R^2 con el mismo procedimiento. Y calcularemos la diferencia entre los modelos para saber cual fue mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e339da9b-3403-40da-a8b1-cf667688d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 del modelo con las variables seleccionadas: 0.3229070119862125\n",
      "\n",
      "La seleccion hacia atras tiene mejor calidad\n",
      "Diferencia entre los dos modelos: 0.007373855793524453\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = X_train[list(sfs.k_feature_names_)]\n",
    "X_test_selected = X_test[list(sfs.k_feature_names_)]\n",
    "\n",
    "estimator.fit(X_train_selected, Y_train)\n",
    "Y_pred = estimator.predict(X_test_selected)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_2 = r2_score(Y_test, Y_pred)\n",
    "print(\"R^2 del modelo con las variables seleccionadas:\", r2)\n",
    "print()\n",
    "\n",
    "if r2_1 > r2_2:\n",
    "    print(\"La seleccion hacia adelante tiene mejor calidad\")\n",
    "    print(\"Diferencia entre los dos modelos:\", r2_1 - r2_2)\n",
    "else:\n",
    "    print(\"La seleccion hacia atras tiene mejor calidad\")\n",
    "    print(\"Diferencia entre los dos modelos:\", r2_2 - r2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78200f0-38e5-436c-8617-308424663b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
